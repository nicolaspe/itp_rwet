{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 05: What are they worried about?\n",
    "\n",
    "For this assignment, I want to create a poem based on questions and ways to answer them. For this, I will use spacy to find questions and their answers. Then, I'll use Markov chains on questions and answers separetely to finally produce some text based on that.\n",
    "\n",
    "As a source material, I'll use the script of the movie [Kiss Kiss Bang Bang](http://www.imdb.com/title/tt0373469/), a noir black comedy film. (I plan to do this with more movies later, but it is difficult to get movie scripts because of how different they all are. Maybe some web scraping tools will help ðŸ™„ðŸ˜…)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT ALL THE PACKAGES!\n",
    "import random as rng\n",
    "from collections import Counter\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File loading and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will load the file, process it with spacy and have a list of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbb_script = [line.strip() for line in open(\"./sources/kisskissbangbang.txt\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbb = nlp( ' '.join(kkbb_script) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences!\n",
    "kkbb_sents = [line.text.strip() for line in list(kkbb.sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what we have\n",
    "kkbb_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some clean-up to do. A lot of '...', '   ' and '-' that need to be erased. But it's hard to discriminate which should be taken away and which one doesn't. The ones I'll clean are \n",
    "- '   ...'\n",
    "- '- '\n",
    "- ' -'\n",
    "- '   -'\n",
    "- '   '\n",
    "\n",
    "But besides that, each line has a sentence, so discriminating between questions and answers will not be that hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbb_cleans = [line.replace('- ','').replace(' -','').replace('   -','').replace('   ...', ' ').replace('   ',' ') for line in kkbb_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbb_cleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much better now!\n",
    "\n",
    "Now, we can create lists of questions and answers. As the sentences have been separated, it is easy to discriminate questions as they will have a '?' sign. And the answer will just be the next line. It is very easy to do a list comprehension to get the questions (`[line for line in kkbb_cleans if '?' in line]`), but we have to expand it to get the next one (the answer). \n",
    "\n",
    "Thankfully, the internet exists and the `zip()` function creates a tupple of two lists. The beauty is that we can use `zip(kkbb_cleans, kkbb_cleans[1:])` to create pairs of two consecutive elements in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['You told your sister she was adopted, yeah?', 'No, I did one better.'],\n",
       " ['What happened, somebody sue you?',\n",
       "  'It used to be \"alakazam\" when you cut me in half.'],\n",
       " ['You hear anything?', \"No, there's nothing in the papers, so....\"],\n",
       " ['What case?', 'Leave her alone.'],\n",
       " ['that the girl in the lake, that was Veronica Dexter?',\n",
       "  'Positive ID, scars, dental records.'],\n",
       " ['You talked to your police guy?', 'Yeah, not much there.'],\n",
       " ['That was the last anybody saw of her? With a symmetrical, ungooshed head.',\n",
       "  'Police ever find the car?'],\n",
       " ['Police ever find the car?', 'No, genius, that was us.'],\n",
       " ['Remember?', 'Oh, yeah, right.'],\n",
       " ['They were?  ', \"The killers were at Dexter's?\"],\n",
       " [\"The killers were at Dexter's?\", \"That's how they recognized you.\"],\n",
       " [', okay?', 'Colin Farrell wants too much money.'],\n",
       " ['Do you get me now?', 'Dabney, he unearths a discovery.'],\n",
       " ['You told her?', 'Pick those up.'],\n",
       " ['Why did you tell her?', \"You didn't have to tell her.\"],\n",
       " ['What, are you threatening me?', 'No, moron.'],\n",
       " ['Remember me?', \"What's up, honey?\"],\n",
       " [\"What's up, honey?\", 'How are you?'],\n",
       " ['How are you?', \"She doesn't want to talk to you.\"],\n",
       " [\"Did you ever think maybe I don't want to talk to her?\",\n",
       "  'I just saw your really distinctive ears.'],\n",
       " ['Is that true?', 'Not really.'],\n",
       " ['Look, she must have a cell phone, right?', 'She must.'],\n",
       " ['No?', 'Come on, I just want to say something to her.'],\n",
       " [\"What's funny?\", 'Nothing.'],\n",
       " [\"What's her stage name?\", 'Ames.'],\n",
       " ['How am I supposed to know?', 'Fuck!'],\n",
       " ['Do you get this?', 'Your case and my case are the same fucking case.'],\n",
       " ['Did I just cut off your finger?', 'Yeah.'],\n",
       " [\"What's my sister's connection to Veronica Dexter?\",\n",
       "  'She predicted that murder, Harry.'],\n",
       " ['You know what else is nuts?', 'You cut off my finger!'],\n",
       " ['How is it?', \"It's fine.\"],\n",
       " [\"Where's Perry?\", 'We gotta find him.'],\n",
       " [\"Remember you said the killer may have been at Dexter's party?\", '-'],\n",
       " ['What if little sis had been murdered by the same assholes... who offed Veronica Dexter?',\n",
       "  'Remember?'],\n",
       " ['Remember?', 'With the ski masks, those dudes.'],\n",
       " ['What do you got?', 'Just now.'],\n",
       " ['If Jenna was hunting her mystery dad, this is where she would start, right?  ',\n",
       "  \"Jesus, don't patronize me!\"],\n",
       " ['What?', 'What is it out here with these women?'],\n",
       " ['What is it out here with these women?',\n",
       "  \"Please, they're no different from anywhere else.\"],\n",
       " ['See that?', 'Obedient little bitches too.'],\n",
       " [\"So who's in this cinematic milestone?\",\n",
       "  'We got a Michael Beck, whoever that is.'],\n",
       " ['What? Nothing.', 'Perry, listen up.'],\n",
       " ['What?  ', \"Who's Har-?\"],\n",
       " [\"Who's Har-?\", 'What?'],\n",
       " ['What?', \"Look, that's-\"],\n",
       " ['Where?', 'In Indiana.'],\n",
       " [\"Do you think I'm stupid?\", \"You wouldn't know where to feed yourself... \"],\n",
       " [\"Harry, don't listen to a word he says, all right?\",\n",
       "  \"We're getting somewhere.\"],\n",
       " [\"What's up, baby?\", 'How you feeling?'],\n",
       " ['How you feeling?', \"I'm just gonnaCome and take a walk.\"],\n",
       " ['What the hell does that mean?', \"I'm with him on this one.\"],\n",
       " ['You do?', '-'],\n",
       " ['Where?', 'At the 1942 Club?'],\n",
       " ['At the 1942 Club?',\n",
       "  \"Just because you didn't get itMotherfucker, I couldSlow your roll.\"],\n",
       " ['What will you do, take me out here?', \"There's sec  Keep talking.\"],\n",
       " ['You wanna know who we are?', \"I'm the frying pan, see?\"],\n",
       " [\"I'm the frying pan, see?\", 'And my boy over here-'],\n",
       " ['Such as why is a savvy, stand-up cat like yourself consorting with gay men?',\n",
       "  'Frolicking in the lake together.'],\n",
       " ['What is that?', \"You're the guys who were wearing the masks.\"],\n",
       " ['All right?', 'How much further to the hospital? Five minutes away.'],\n",
       " ['How much further to the hospital? Five minutes away.', 'Talk to me.'],\n",
       " ['Our mascot, back in high school, who was it?',\n",
       "  'Come on, Harry, stay with me.'],\n",
       " [\"You said it's a black guy and a white guy?\", \"You're right.\"],\n",
       " ['Are we slowing down?', \"No, I'm getting a pen.\"],\n",
       " ['Are you following them?', 'Better not be.'],\n",
       " ['What?', 'Holy shit.'],\n",
       " ['All right?', 'Cool?'],\n",
       " ['Cool?', 'Yeah.'],\n",
       " ['Shit, if I leave the keys, can you take yourself to the hospital?',\n",
       "  'Oh, yeah, sure.'],\n",
       " ['You what? Perry!', 'Now, where you going?'],\n",
       " ['Now, where you going?', 'No, no, no.'],\n",
       " ['Where the hell did you come from?  ', 'He got away.'],\n",
       " ['Hello?', 'Anyone home?'],\n",
       " ['Anyone home?', 'Hello?'],\n",
       " ['Hello?', 'Anyone home?'],\n",
       " ['Anyone home?', 'I got an injury problem.'],\n",
       " ['We can absolutely talk about it, all right?', 'Thank you.'],\n",
       " ['Promise?', 'Yep.'],\n",
       " ['Who are you?', 'Who are you?'],\n",
       " ['Who are you?', 'Who-?'],\n",
       " ['Who-?', 'Well, hey.'],\n",
       " ['So you still here, huh, tough guy?', 'Oh, you got a gun, I see.'],\n",
       " ['Yeah?', 'What?'],\n",
       " ['What?', 'Where the hell are you?'],\n",
       " ['Where the hell are you?', \"I'm with one of the kidnappers.\"],\n",
       " ['Harry?', 'Harry?'],\n",
       " ['Harry?', 'Hey, Perry, I shot a guy.'],\n",
       " ['So this evening, was it Jonny Gossamer enough for you?',\n",
       "  'To tell you the truth, Jonny Gossamer always has a way bigger ending.'],\n",
       " [\"So this thing, it's over, right?\",\n",
       "  'They say the kidnappers are all dead, so....'],\n",
       " ['If she stumbles on a murder plot, why hire me to film it?',\n",
       "  'Why not simply go to the police?'],\n",
       " ['Why not simply go to the police?', 'Right.'],\n",
       " ['So the whole reconcilement thing?', '\"Reconciliation,\" idiot.'],\n",
       " [\"Suddenly they're inseparable?\", 'So, what are you saying?'],\n",
       " ['So, what are you saying?', \"We're gonna, like, probe deeper?\"],\n",
       " [\"We're gonna, like, probe deeper?\", 'Absolutely not.'],\n",
       " ['What?', 'What are you talking about?'],\n",
       " ['What are you talking about?', 'My sister paid you.'],\n",
       " [\"What, you're gonna bail? Harmony... \",\n",
       "  \"do you want your sister's money back?\"],\n",
       " [\"do you want your sister's money back?\", 'Done.'],\n",
       " ['You wanna come up?', \"No, I don't wanna come up.\"],\n",
       " ['Why would I go up there?', 'They cleaned it.'],\n",
       " ['You know what, Harry?', 'Stop.'],\n",
       " [\"Why'd you lie to me?\", 'It was an excuse to stay around you.'],\n",
       " ['And who would that be?', \"You think I'm-\"],\n",
       " ['You know what?', 'It worked.'],\n",
       " [\"My opinion doesn't count?\", \"No, it doesn't.\"],\n",
       " ['Come again?', \"That's what I do for a living.\"],\n",
       " ['Why?', 'Just turn around.'],\n",
       " [\"What, my tag's out?\", 'This dump have a bar?'],\n",
       " ['This dump have a bar?', 'Yeah.'],\n",
       " ['God, Harry, where are you going with this?', 'No, no, no.'],\n",
       " [\"Didn't really turn out the way we hoped, did it?\",\n",
       "  'I guess if I racked my brain, I could think of worse places to be.'],\n",
       " ['Is that so, Whitey?', 'Whitey?'],\n",
       " ['Whitey?', 'Calling me a knight?'],\n",
       " ['Calling me a knight?', 'Maybe, yeah.'],\n",
       " ['What?', 'Stop.'],\n",
       " ['Why not?', \"I don't want you to offer it\"],\n",
       " ['He looked sad?', 'Yes, he did.'],\n",
       " ['Harry, was she raped?', 'The Dexter girl, was she raped?'],\n",
       " ['The Dexter girl, was she raped?',\n",
       "  \"No, the ME's report showed no indication of rape stuff.\"],\n",
       " [\"What's up?\", \"Harmony's in trouble.\"],\n",
       " ['What did you say to her?', 'Nothing.'],\n",
       " [\"You're not worried?\", 'Of course.'],\n",
       " ['Now, what did you say?', 'Think.'],\n",
       " ['What?', 'I tell him about destiny.'],\n",
       " ['And you?', 'How about it, filmgoer?'],\n",
       " ['How about it, filmgoer?',\n",
       "  'Have you solved the case of the dead people in L.A.?'],\n",
       " ['Have you solved the case of the dead people in L.A.?',\n",
       "  \"Times Square audiences, don't shout at the screen.\"],\n",
       " ['How are you doing tonight?', 'They gave away my crickets.'],\n",
       " [\"Excuse me, you wouldn't, by chance, happen to have seen this woman?\",\n",
       "  'No.'],\n",
       " [\"How could she be here and meanwhile, she's out having parties?\", 'Think.'],\n",
       " ['Why?', \"I'll tell you why.\"],\n",
       " [\"So it's two different girls, right?\",\n",
       "  'He stashed his daughter in here, and then he put the ringer on the street.'],\n",
       " ['So where did she go from here?', \"Shut up, I'm thinking.\"],\n",
       " [\"Doesn't that suck?\", 'I just hit you for no reason.'],\n",
       " [\"You don't get it, do you?\", 'This isn\\'t \"good cop, bad cop. \"'],\n",
       " ['For chrissake, who are you protecting?', \"It's all over.\"],\n",
       " ['Then he had to kill her, huh?', 'Put a sock in it.'],\n",
       " ['Okay?', 'And for the record, it was the boyfriend, the guy from Paris.'],\n",
       " ['Am I right?', 'Fuck you!'],\n",
       " [\"You think that's funny, huh?\", \"I'm gonna break your nose now.\"],\n",
       " ['Can you do that for me?', 'Fuck you.'],\n",
       " ['Ambiguous?', \"I don't think so.\"],\n",
       " ['He means when you say, \"Picture it inside your head\"... is that \"a bullet will be inside your head\"... or \"picture it in your head\"?',\n",
       "  'Harry, will you shut up.'],\n",
       " ['Harry, what are you doing?',\n",
       "  \"What I'm doing for the guy who likes to bluff...\"],\n",
       " ['...is I\\'m playing a little game called \"Am I Bluffing?',\n",
       "  '\" Where is she?'],\n",
       " ['\" Where is she?', 'Where the fuck is Harmony?'],\n",
       " ['Where the fuck is Harmony?', 'You want to play hardball?'],\n",
       " ['You want to play hardball?', 'Where is the girl?'],\n",
       " ['Where is the girl?', 'What did you just do?'],\n",
       " ['What did you just do?', \"I just put in one bullet, didn't I?\"],\n",
       " [\"I just put in one bullet, didn't I?\", 'You put a live round in that gun?'],\n",
       " ['You put a live round in that gun?',\n",
       "  'Yeah, there was like an 8 percent chance.'],\n",
       " ['Eight?', 'Who taught you math?'],\n",
       " ['Who taught you math?', 'Maybe it was more.'],\n",
       " ['Hello? Perry, is that you?', \"Hey, it's me.\"],\n",
       " [\"What's going on?\", 'Where are you?  '],\n",
       " ['Where are you?  ', 'At home.'],\n",
       " [\"You're at home?\", 'I just got back.'],\n",
       " [\"Why aren't you following your lead?\", 'Oh, forget it.'],\n",
       " ['What do you say, Perry?', 'Oh, fuck, no fair.'],\n",
       " ['You ever think about that?', 'He did, Harry.'],\n",
       " ['Yeah, you ready?', 'Speak of the devil.'],\n",
       " [\"Aurelio, why don't you give the kid a break?\",\n",
       "  'Do unto others and all that.'],\n",
       " ['Who else knows?', \"I don't know anything.\"],\n",
       " [\"You like looking at his johnson, don't you?\",\n",
       "  'Admit it, dude, you got it in you.'],\n",
       " [\"That's what you want, isn't it?\", 'You want to fuck me.'],\n",
       " ['You want some of this right here?', 'Look at this.'],\n",
       " ['Are you okay?', 'Not really, no.'],\n",
       " [\"Who's driving?\", \"I tell you what, I'll flip you for it.\"],\n",
       " ['Oh, God, how did you get away?',\n",
       "  'I shot him with a small revolver I keep near my balls.'],\n",
       " ['Can you pick us up?', \"I'm in a van with the body.\"],\n",
       " [\"Perry, what's wrong?\", 'Come on, breathe.'],\n",
       " ['Did you call me?', \"Harry, you're shot.\"],\n",
       " ['Look, you want to see something cool?', 'Cool!'],\n",
       " ['How many fingers?', \"Put that cat down, because I'm allergic.\"],\n",
       " ['You feeling okay?', \"How's your...?\"],\n",
       " [\"How's your...?\", 'My what?'],\n",
       " ['My what?', 'Well, your.... Everything down there.'],\n",
       " [\"It's Christmas, where's my present, Slick?\",\n",
       "  \"Your present is you're not in jail, fag-hag.\"],\n",
       " ['but what do you want me to do, lie about it?',\n",
       "  'So you found something out?'],\n",
       " ['So you found something out?', 'Yeah.'],\n",
       " [\"Do you see where I'm going with this?\",\n",
       "  'One day your sister came calling, and she saw Dexter... '],\n",
       " ['How about you?', 'Did your father love you?'],\n",
       " ['Did your father love you?', 'Sometimes.'],\n",
       " ['How about yours?',\n",
       "  \"Well, he used to beat me in Morse code, so it's possible... \"],\n",
       " ['What?', \"Don't steal any more shit.\"],\n",
       " ['You like that, huh?', 'I saw him in the commissary twice.'],\n",
       " ['What is he, like 6\\'4\"?', \"He doesn't know he's gay.\"],\n",
       " ['Do I know you?', 'No.'],\n",
       " ['What do you want?',\n",
       "  \"The zoo was closed, so I thought I'd come here and look at an animal.\"],\n",
       " [\"Who do you think you're talking to?\", 'I buried my daughter today.'],\n",
       " ['Who are you?', 'I loved my girl.'],\n",
       " ['Yeah?', \"Well, you can't.\"],\n",
       " ['I prefer Genaros, but what do I know?', \"I'm a bear.\"],\n",
       " ['That was some pretty harsh shit with the old guy back there, right?',\n",
       "  \"But whatever, he's creepy.\"],\n",
       " ['What are you doing?', \"I'm trying to wrap up the movie... \"]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_a_lines = [[q_line, a_line] for q_line,a_line in zip(kkbb_cleans, kkbb_cleans[1:]) if '?' in q_line]\n",
    "q_a_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just have to separate the lines into questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkbb_q = [pair[0] for pair in q_a_lines]\n",
    "kkbb_a = [pair[1] for pair in q_a_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov analysis\n",
    "\n",
    "First, let's generate a function that generates the tuples from each question. These analysis could be character by character or word by word. I'm more interested in the latter, as I want to recreate the worries and questions from the characters in the movie. \n",
    "\n",
    "Another particular choice is how to separate the words in each question or answer. Is \"Who\" the same as \"Who's\"? Or will they have separate values (\"Who\" and \"'s\") for the markov analysis? I will let technology decide (not really) and use nlp on eaach of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_q = nlp( ' '.join(kkbb_q) )\n",
    "q_words = [item.text for item in nlp_q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and let's see if I got what I wanted\n",
    "\"'s\" in q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for the answers\n",
    "nlp_a = nlp( ' '.join(kkbb_a) )\n",
    "a_words = [item.text for item in nlp_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aparrish_doc = nlp(\"who's on first? I am.\")\n",
    "aparrish_words = [item.text for item in aparrish_doc]\n",
    "aparrish_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(aparrish_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aparrish_words2 = [item.text_with_ws for item in aparrish_doc]\n",
    "aparrish_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(aparrish_words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, onto the model generation. I will use word ngrams of length 2, as I'm not really sure of what will turn up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(q_words[-1])\n",
    "print(a_words[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_model(list_source, n):\n",
    "    model = {}\n",
    "    # append None to the end of the list - I'm not sure...\n",
    "#     source = list(list_source) + [None]\n",
    "    source = list(list_source)\n",
    "    # and we go over the source list\n",
    "    for i in range( len(source)-n  ):\n",
    "        # grab the key AS A TUPLE!\n",
    "        key = tuple(source[i:i+n])\n",
    "        # find if that key exists already in the model\n",
    "        if key not in model:\n",
    "            # initialize the dictionary entry\n",
    "            model[key] = []\n",
    "        # append the value it leads to\n",
    "        model[key].append( source[i+n] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = markov_model(q_words, 2)\n",
    "a_model = markov_model(a_words, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the scripts\n",
    "\n",
    "Now to the testing... I don't really have an \"escape\" route in each model. I could have appended 'None' to each '?' symbol, but I want to be able to create multiple questions if I want to. \n",
    "\n",
    "So, first, I need to create two generation functions to use the chain and get a desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(list_start, model):\n",
    "    # initialize output\n",
    "    output = list(list_start)\n",
    "    # iterate a lot to get a question\n",
    "    for i in range(20):\n",
    "        # transform the start list into a tuple (so it can be used as key)\n",
    "        key = tuple(output[-2:])\n",
    "        # search for the next word and append it\n",
    "        word = rng.choice( model[key] )\n",
    "        output.append(word)\n",
    "        # check for stopping case\n",
    "        if '?' == word:\n",
    "            break\n",
    "    # transform the output to a string and return\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(list_start, model):\n",
    "    # initialize output\n",
    "    output = list(list_start)\n",
    "    # iterate a lot to get a question\n",
    "    for i in range(40):\n",
    "        # transform the start list into a tuple (so it can be used as key)\n",
    "        key = tuple(output[-2:])\n",
    "        # search for the next word and append it\n",
    "        word = rng.choice( model[key] )\n",
    "        output.append(word)\n",
    "        # check for stopping case\n",
    "        if '...' == word or '.' == word:\n",
    "            break\n",
    "    # transform the output to a string and return\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What 's going on ?\n"
     ]
    }
   ],
   "source": [
    "# let's test them!\n",
    "print( get_question([\"What\",\"'s\"], q_model) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got back .\n"
     ]
    }
   ],
   "source": [
    "print( get_answer([\"I\",\"just\"], a_model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final problem is how to select two words for each start case. As I have a list of all the questions and answers, the first thing I'll try is to extract the first two words from each, and see where that gets me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_nlp_starts = [nlp(line) for line in kkbb_q]\n",
    "q_starts = [ (words[0].text,words[1].text) for words in q_nlp_starts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Attempt to access token at 1, max length 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d1caf709d5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma_nlp_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkkbb_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_nlp_starts\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-d1caf709d5aa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma_nlp_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkkbb_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma_nlp_starts\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mtoken.pxd\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.cinit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Attempt to access token at 1, max length 1"
     ]
    }
   ],
   "source": [
    "a_nlp_starts = [nlp(line) for line in kkbb_a]\n",
    "a_starts = [ (words[0].text,words[1].text) for words in a_nlp_starts ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I got an error, because the list has some length 1 sentences. As nlp separates '.' as a word, the only problem is the multiple occurrance of '-'. As the `remove()` function only takes out the word once, I will create a small function that does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all(source_list, target):\n",
    "    while target in source_list:\n",
    "        source_list.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all(kkbb_a, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-' in kkbb_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try again\n",
    "a_nlp_starts = [nlp(line) for line in kkbb_a]\n",
    "a_starts = [ (words[0].text,words[1].text) for words in a_nlp_starts ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there's any recurring pairs in each of the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('What', '?'), 10),\n",
       " (('What', \"'s\"), 7),\n",
       " (('Do', 'you'), 4),\n",
       " (('What', ','), 3),\n",
       " (('You', 'know'), 3),\n",
       " (('What', 'do'), 3),\n",
       " (('What', 'is'), 3),\n",
       " (('Harry', ','), 3),\n",
       " (('Where', 'the'), 3),\n",
       " (('Hello', '?'), 3),\n",
       " (('Who', 'are'), 3),\n",
       " (('How', 'about'), 3),\n",
       " (('You', 'told'), 2)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pairs = Counter(q_starts)\n",
    "q_pairs.most_common(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('No', ','), 10),\n",
       " (('I', \"'m\"), 8),\n",
       " (('Oh', ','), 5),\n",
       " (('I', 'just'), 4),\n",
       " (('Yeah', '.'), 4),\n",
       " (('Well', ','), 4),\n",
       " (('Come', 'on'), 3),\n",
       " (('I', 'do'), 3),\n",
       " (('Yeah', ','), 2),\n",
       " (('That', \"'s\"), 2),\n",
       " (('Not', 'really'), 2),\n",
       " (('Nothing', '.'), 2),\n",
       " (('It', \"'s\"), 2)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pairs = Counter(a_starts)\n",
    "a_pairs.most_common(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good enough to do some interesting things. I'll pick only the pairs that have 3 or more repetitions to have a better spread of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No', ',')\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(a_pairs.most_common(10)[0][0])\n",
    "print(a_pairs.most_common(10)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['No', ','],\n",
       " ['I', \"'m\"],\n",
       " ['Oh', ','],\n",
       " ['I', 'just'],\n",
       " ['Yeah', '.'],\n",
       " ['Well', ','],\n",
       " ['Come', 'on'],\n",
       " ['I', 'do']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_common = [ list(item[0]) for item in a_pairs.most_common() if item[1] >= 3]\n",
    "a_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', '?'],\n",
       " ['What', \"'s\"],\n",
       " ['Do', 'you'],\n",
       " ['What', ','],\n",
       " ['You', 'know'],\n",
       " ['What', 'do'],\n",
       " ['What', 'is'],\n",
       " ['Harry', ','],\n",
       " ['Where', 'the'],\n",
       " ['Hello', '?'],\n",
       " ['Who', 'are'],\n",
       " ['How', 'about']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_common = [ list(item[0]) for item in q_pairs.most_common() if item[1] >= 3]\n",
    "q_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can finally do something with all this! ðŸ˜ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LET'S HAVE FUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple dialog\n",
    "\n",
    "First, let's create a simple dialog alternating some q&a's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where the fuck is Harmony ?\n",
      "I 'm a bear .\n",
      "\n",
      "\n",
      "How about you ?\n",
      "No , there was like an 8 percent chance .\n",
      "\n",
      "\n",
      "What do you ?\n",
      "Come on , Harry .\n",
      "\n",
      "\n",
      "Hello ? Anyone home ?\n",
      "I 'm thinking .\n",
      "\n",
      "\n",
      "What ? What is he , like 6'4 \" ?\n",
      "I 'm getting a pen .\n",
      "\n",
      "\n",
      "Harry , where you going ?\n",
      "I do n't want to say something to her .\n",
      "\n",
      "\n",
      "How about you ?\n",
      "Yeah . She predicted that murder , Harry .\n",
      "\n",
      "\n",
      "You know what else is nuts ?\n",
      "Yeah . She predicted that murder , Harry .\n",
      "\n",
      "\n",
      "Hello ? Anyone home ?\n",
      "I just put in one bullet , did n't get itMotherfucker , I couldSlow your roll .\n",
      "\n",
      "\n",
      "What 's my sister 's money back ?\n",
      "Yeah . Oh , you got it in you .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    q_cue = rng.choice(q_common) #haha\n",
    "    print( get_question(q_cue, q_model) )\n",
    "    \n",
    "    a_cue = rng.choice(a_common)\n",
    "    print( get_answer(a_cue, a_model) )\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A world full of questions\n",
    "\n",
    "We have so many questions. The world is a horrible place. Can we answer all of these with one sentence? \n",
    "\n",
    "(Idea: make this again, but with the script of \"The Hitchhicker's Guide to the Galaxy\" and see how many questions can we reply with \"42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What 's my present , Slick ?\n",
      "What 's up ?\n",
      "What 's funny ?\n",
      "Do you get me now ?\n",
      "What do you say , Perry ?\n",
      "\n",
      "\n",
      "Yeah . One day your sister 's money back ? Done .\n"
     ]
    }
   ],
   "source": [
    "for i in range(rng.randrange(5,15)):\n",
    "    q_cue = rng.choice(q_common) #haha again\n",
    "    print( get_question(q_cue, q_model) )\n",
    "\n",
    "print('\\n')\n",
    "a_cue = rng.choice(a_common)\n",
    "print( get_answer(a_cue, a_model) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is it out here ?\n",
      "What do you want , is that \" a bullet will be inside your head \" ... is that ?\n",
      "Harry , what are you doing tonight ?\n",
      "How about you ?\n",
      "What do you want your sister 's connection to Veronica Dexter ?\n",
      "You know what else is nuts ?\n",
      "You know what else is nuts ?\n",
      "Harry , where you going with this ?\n",
      "Harry , where you going ?\n",
      "What , my tag 's out having parties ?\n",
      "What ? All right ?\n",
      "What do you ?\n",
      "What , are you doing ?\n",
      "\n",
      "\n",
      "No , the guy who likes to bluff ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(rng.randrange(5,15)):\n",
    "    q_cue = rng.choice(q_common) #haha again\n",
    "    print( get_question(q_cue, q_model) )\n",
    "\n",
    "print('\\n')\n",
    "a_cue = rng.choice(a_common)\n",
    "print( get_answer(a_cue, a_model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4s\n",
    "\n",
    "I want to create small songs using questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rng.randrange(4, 8)):\n",
    "    num_q = rng.randrange(1,3)\n",
    "    for j in range(num_q):\n",
    "        q_cue = rng.choice(q_common) #haha doesn't get old\n",
    "        print( get_question(q_cue, q_model) )\n",
    "    for k in range(4-num_q):\n",
    "        a_cue = rng.choice(a_common)\n",
    "        print( get_answer(a_cue, a_model) )\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
