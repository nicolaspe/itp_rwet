{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Finding rhyming alternate wording\n",
    "Here, I will revisit my third assignment -where I mashed some existing poems and texts- and try to give it some rhythmic components using similar words and phonetic proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python packages\n",
    "import random as rng\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pronouncing\n",
    "import pronouncing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text sources\n",
    "I will use Eileen Myles' poems *\"Peanut Butter\"*, *\"Each Defeat\"* and *\"Our Happiness\"* as source poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = [line.strip() for line in open('./sources/eileen_peanutbutter.txt', 'r')]\n",
    "poems.extend([line.strip() for line in open('./sources/eileen_eachdefeat.txt', 'r')])\n",
    "poems.extend([line.strip() for line in open('./sources/eileen_ourhappiness.txt', 'r')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to filter out the empty lines from these texts. I could use list comprehension, but of course there is a faster and better way to do it, which someone in stackoverflow has posted about\n",
    "\n",
    "Source: https://stackoverflow.com/questions/3845423/remove-empty-strings-from-a-list-of-strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = list(filter(None, poems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in ponds &',\n",
       " 'laundry. I just saw a coyote',\n",
       " 'instant mouth',\n",
       " 'Yellow, just kind',\n",
       " 'in the vastly']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.sample(poems, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for similarity\n",
    "\n",
    "Let's create some functions and load all the tokens to use the word2vec information later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(set([w.text for w in nlp(' '.join(poems)) if w.is_alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spacy vector\n",
    "def vec(s):\n",
    "    return nlp.vocab[s].vector\n",
    "\n",
    "# cosine similarity\n",
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# closest word to target vector from token list\n",
    "def spacy_closest(token_list, vec_to_check, n=10):\n",
    "    return sorted(token_list, key=lambda x: cosine(vec_to_check, vec(x)), reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokens form a list of words\n",
    "def token_list(words):\n",
    "    return list(set([w.text for w in nlp(' '.join(words)) if w.is_alpha]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding rhyming alternate wording\n",
    "\n",
    "I want to derive words from a random line of the poems. This will replicate the rhytmic pattern and will be picked based on the similarity to the source word.\n",
    "\n",
    "Sources: https://stackoverflow.com/questions/26132770/python-finding-longest-shortest-words-in-a-list-and-calling-them-in-a-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_word(line):\n",
    "    words = line.split(' ')\n",
    "    sortedwords = sorted(words, key=len)\n",
    "    return words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing what I want to do with one line\n",
    "test_line = rng.sample(poems, 1)[0]\n",
    "test_word = longest_word(test_line)\n",
    "test_stress = pronouncing.stresses(test_word)\n",
    "test_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sand-'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great that this happened right away, because it reminds me that I need to:\n",
    "- filter some characters from the poem or line or word I select\n",
    "- need to be aware that pronouncing returns an empty character if the word is not on it's list\n",
    "\n",
    "And, as I will do this a lot of times, I will just create a function that iterates over the words to find the perfect one. And as I'm already using spacy, I'll use nlp to separate the words (there are so many punctuation characters that will ruin everything!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_words(line, n=10):\n",
    "    # filter characters\n",
    "    words = [item.text for item in nlp(line)]\n",
    "    # sort them from longest to shortest\n",
    "    sorted_words = sorted(words, key=len, reverse=True)\n",
    "    # go through them searching for a word that exists in the pronouncing library\n",
    "    for w in sorted_words:\n",
    "        chosen_word = w\n",
    "        word_phones = pronouncing.phones_for_word(w)[0]\n",
    "        stress = pronouncing.stresses(word_phones)\n",
    "        if stress is not '':\n",
    "            break\n",
    "    # look for words with similar stresses\n",
    "    similar_stresses = pronouncing.search_stresses('^'+stress+'$')\n",
    "    # get the ones closest to the starting word\n",
    "    sim_stress_tokens = token_list(similar_stresses)\n",
    "    chosen_vec = vec(chosen_word)\n",
    "    # and return some of them\n",
    "    closest_words = spacy_closest(sim_stress_tokens, chosen_vec, n)\n",
    "    return [chosen_word, closest_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman with\n",
      "woman\n",
      "['woman', 'lady', 'women', 'mother', 'pregnant', 'prego', 'boy', 'youngster', 'husband', 'men']\n"
     ]
    }
   ],
   "source": [
    "# let's test it!\n",
    "test_line = rng.sample(poems, 1)[0]\n",
    "print(test_line)\n",
    "\n",
    "test_match = perfect_words(test_line)\n",
    "print(test_match[0])\n",
    "print(test_match[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!\n",
    "\n",
    "Now, on to testing with some creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each defeat, defeats, prevailed, against\n"
     ]
    }
   ],
   "source": [
    "# FORM 1\n",
    "\n",
    "# get a line\n",
    "line = rng.choice(poems)\n",
    "# find the similarly stressed ones\n",
    "simil = perfect_words(line, 4)\n",
    "word_chosen = simil[0]\n",
    "word_rhymes = simil[1]\n",
    "# recreate the line with the rhytmic synonyms\n",
    "new_line = line.replace(word_chosen, ', '.join(word_rhymes))\n",
    "print(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we sat on a stoop\n",
      "we sat on a wined\n",
      "we sat on a tarred\n",
      "we sat on a shames\n"
     ]
    }
   ],
   "source": [
    "# FORM 2\n",
    "\n",
    "# get a line\n",
    "line = rng.choice(poems)\n",
    "# find the similarly stressed ones\n",
    "simil = perfect_words(line)\n",
    "word_chosen = simil[0]\n",
    "word_rhymes = simil[1]\n",
    "# recreate the line with the rhytmic synonyms\n",
    "for i in range( min(len(word_rhymes),4) ):\n",
    "    new_line = line\n",
    "    print(new_line.replace(word_chosen, word_rhymes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, this doesn't make that much sense in these poems. The lines are too short to get anything midly interesting. And it fails quite often ðŸ˜©\n",
    "\n",
    "It seems like this idea was never too good, so I'll just move away from it. A better option might be doing this on texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maniac characters\n",
    "\n",
    "It would be better to make someone say a long line of text and then, repeat the last bit with some differences every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_doc  = kkbb_script = [line.strip() for line in open(\"./sources/emmeline_iincitethismeetingtorebellion.txt\").readlines()]\n",
    "em_text = nlp( ' '.join(em_doc) )\n",
    "em_sent = [line.text.strip() for line in list(em_text.sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['principle', '-', 'do', 'so', '.']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_line = rng.choice(em_sent)\n",
    "em_line_words = [item.text for item in nlp(em_line)]\n",
    "em_line_end = em_line_words[-5:]\n",
    "em_line_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a lot of punctuation signs, I need to get rid of those before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_punct(word_list):\n",
    "    banned = ['-', ',', '.', '_', '!', ';', ':', '?', '\"', \"'\"]\n",
    "    return [item for item in word_list if item not in banned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keep', 'me', 'in', 'prison']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_line = rng.choice(em_sent)\n",
    "em_line_words = [item.text for item in nlp(em_line)]\n",
    "em_line_end = no_punct(em_line_words[-5:])\n",
    "em_line_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of them tell us that other things are more important than the liberty of women-than the liberty of working women.\n",
      "liberties of working women.\n",
      "minuteman of working women.\n",
      "servitude of working women.\n",
      "overturn of working women.\n",
      "\n",
      "It is not the method of women.\n",
      "the methods of women.\n",
      "the using of women.\n",
      "the constants of women.\n",
      "the linkage of women.\n",
      "\n",
      "There is something that governments care far more for than human life, and that is the security of property, and so it is through property that we shall strike the enemy.\n",
      "shall strikes the enemy.\n",
      "shall struck the enemy.\n",
      "shall force the enemy.\n",
      "shall hit the enemy.\n",
      "\n",
      "Be militant each in your own way.\n",
      "in you own way.\n",
      "in our own way.\n",
      "in own own way.\n",
      "in my own way.\n",
      "\n",
      "It is better that those who cannot agree, cannot see eye to eye as to policy, should set themselves free, should part, and should be free to continue their policy as they see it in their own way, unfettered by those with whom they can no longer agree.\n",
      "can no even agree.\n",
      "can no shorter agree.\n",
      "can no longish agree.\n",
      "can no not agree.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    em_line = rng.choice(em_sent)\n",
    "    em_line_words = [item.text for item in nlp(em_line)]\n",
    "    em_line_end = em_line_words[-5:]\n",
    "    result = perfect_words( ' '.join(no_punct(em_line_end)) )\n",
    "    word_chosen = result[0]\n",
    "    word_simil = result[1]\n",
    "    print(em_line)\n",
    "    for j in range(min(len(word_simil)-1,4)):\n",
    "        new_line = ' '.join(em_line_end).replace(word_chosen, word_simil[j+1]).replace(' .','.')\n",
    "        print(new_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
